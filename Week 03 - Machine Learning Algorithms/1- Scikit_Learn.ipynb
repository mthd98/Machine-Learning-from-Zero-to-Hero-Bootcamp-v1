{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "cLHAiAzQEqU2"
      },
      "source": [
        "# Scikit-Learn\n",
        "\n",
        "<!--<badge>--><a href=\"https://colab.research.google.com/github/mthd98/Machine-Learning-from-Zero-to-Hero-Bootcamp-v1/blob/main/Week 03 - Machine Learning Algorithms/1- Scikit_Learn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a><!--</badge>-->\n",
        "\n",
        "\n",
        "[Scikit-learn](http://scikit-learn.org/stable/) is a python-based machine learning library providing implementations of a great many algorithms for supervised and unsupervised learning. In large part, it builds upon the cabilities of NumPy, SciPy, matplotlib, and Pandas.\n",
        "\n",
        "In the context of supervised learning, the primary objects scikit-learn defines are called **estimators**. Each of these defines a `fit` method, which develops a model from provided training data, and a `predict` method, which uses the model to map a new instance to a suitable target value. Scikit-learn also defines multiple utilities for partitioning and manipulating data sets as well as evaluating models.\n",
        "\n",
        "Below, we cover some of the basic steps needed to create a model in scikit-learn.  These notes are based on material appearing in the *scikit-learn tutorials*.\n",
        "\n",
        "*  [Tutorial](http://scikit-learn.org/stable/tutorial/index.html)\n",
        "*  [Cheatsheet](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Scikit_Learn_Cheat_Sheet_Python.pdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvzKfYgXEqVC"
      },
      "source": [
        "## Datasets\n",
        "\n",
        "Scikit-learn comes bundled with several pre-defined (typically small) `datasets` that users can explore.\n",
        "\n",
        "    load_boston()\tLoad and return the boston house-prices dataset (regression).\n",
        "    load_iris()\tLoad and return the iris dataset (classification).\n",
        "    load_diabetes()\tLoad and return the diabetes dataset (regression).\n",
        "    load_digits()\tLoad and return the digits dataset (classification).\n",
        "    load_linnerud()\tLoad and return the linnerud dataset (multivariate regression).\n",
        "    load_wine()\tLoad and return the wine dataset (classification).\n",
        "    load_breast_cancer()\tLoad and return the breast cancer wisconsin dataset (classification).\n",
        "\n",
        "The iris dataset is loaded below, and a description of it is printed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tPAFLH3AEqVD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# using 'from * import ...' allows as to import submodules directly\n",
        "from sklearn import (\n",
        "    datasets,\n",
        "    model_selection,\n",
        "    linear_model,\n",
        "    metrics,\n",
        "    neighbors,\n",
        "    tree,\n",
        "    ensemble,\n",
        "    preprocessing,\n",
        ")\n",
        "\n",
        "# alternatively, we can import the whole package as such\n",
        "import sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 850,
          "status": "ok",
          "timestamp": 1655312921916,
          "user": {
            "displayName": "Muntadher Al-kaabi",
            "userId": "00221067971932357642"
          },
          "user_tz": -180
        },
        "id": "FARFibuOuHaw",
        "outputId": "bb6e52cd-d142-4fa0-d857-7efb43aa353a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ".. _iris_dataset:\n",
            "\n",
            "Iris plants dataset\n",
            "--------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 150 (50 in each of three classes)\n",
            "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
            "    :Attribute Information:\n",
            "        - sepal length in cm\n",
            "        - sepal width in cm\n",
            "        - petal length in cm\n",
            "        - petal width in cm\n",
            "        - class:\n",
            "                - Iris-Setosa\n",
            "                - Iris-Versicolour\n",
            "                - Iris-Virginica\n",
            "                \n",
            "    :Summary Statistics:\n",
            "\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "                    Min  Max   Mean    SD   Class Correlation\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
            "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
            "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
            "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "    :Class Distribution: 33.3% for each of 3 classes.\n",
            "    :Creator: R.A. Fisher\n",
            "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
            "    :Date: July, 1988\n",
            "\n",
            "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
            "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
            "Machine Learning Repository, which has two wrong data points.\n",
            "\n",
            "This is perhaps the best known database to be found in the\n",
            "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
            "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
            "data set contains 3 classes of 50 instances each, where each class refers to a\n",
            "type of iris plant.  One class is linearly separable from the other 2; the\n",
            "latter are NOT linearly separable from each other.\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
            "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
            "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
            "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
            "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
            "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
            "     Structure and Classification Rule for Recognition in Partially Exposed\n",
            "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
            "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
            "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
            "     on Information Theory, May 1972, 431-433.\n",
            "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
            "     conceptual clustering system finds 3 classes in the data.\n",
            "   - Many, many more ...\n"
          ]
        }
      ],
      "source": [
        "iris_dataset = (\n",
        "    datasets.load_iris()\n",
        ")  # sklearn.datasets.load_iris() works exactly the same\n",
        "\n",
        "print(iris_dataset.DESCR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idq1o-aou6WR"
      },
      "source": [
        "We can also use `iris_dataset.data` and `iris_dataset.targets` to create or x & y (inputs & outputs) pairs that will be used for training and testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "executionInfo": {
          "elapsed": 32,
          "status": "ok",
          "timestamp": 1655312925923,
          "user": {
            "displayName": "Muntadher Al-kaabi",
            "userId": "00221067971932357642"
          },
          "user_tz": -180
        },
        "id": "JbXkcYblu6DT",
        "outputId": "0ead5436-2f61-4296-84f7-c5325c204a2c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2400a163-be6c-4db2-ae4a-774bf1e48c09\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length (cm)</th>\n",
              "      <th>sepal width (cm)</th>\n",
              "      <th>petal length (cm)</th>\n",
              "      <th>petal width (cm)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>6.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>6.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>6.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>6.2</td>\n",
              "      <td>3.4</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>5.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows \u00d7 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2400a163-be6c-4db2-ae4a-774bf1e48c09')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2400a163-be6c-4db2-ae4a-774bf1e48c09 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2400a163-be6c-4db2-ae4a-774bf1e48c09');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
              "0                  5.1               3.5                1.4               0.2\n",
              "1                  4.9               3.0                1.4               0.2\n",
              "2                  4.7               3.2                1.3               0.2\n",
              "3                  4.6               3.1                1.5               0.2\n",
              "4                  5.0               3.6                1.4               0.2\n",
              "..                 ...               ...                ...               ...\n",
              "145                6.7               3.0                5.2               2.3\n",
              "146                6.3               2.5                5.0               1.9\n",
              "147                6.5               3.0                5.2               2.0\n",
              "148                6.2               3.4                5.4               2.3\n",
              "149                5.9               3.0                5.1               1.8\n",
              "\n",
              "[150 rows x 4 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = pd.DataFrame(iris_dataset.data, columns=iris_dataset.feature_names)\n",
        "y = pd.DataFrame(iris_dataset.target, columns=[\"Labels\"])\n",
        "\n",
        "x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5S3W8bkDuvH4"
      },
      "source": [
        "Alternatively, can  load a dataset into x & y directly (i.e. into input/output pairs) by setting the `return_X_y` parameter to `True`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 6,
          "status": "ok",
          "timestamp": 1655312926631,
          "user": {
            "displayName": "Muntadher Al-kaabi",
            "userId": "00221067971932357642"
          },
          "user_tz": -180
        },
        "id": "IqmQMvHbuuZq",
        "outputId": "5a789103-3af9-431b-ab9e-c66fccd07d73"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((150, 4), (150,))"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x, y = datasets.load_iris(return_X_y=True)\n",
        "\n",
        "x.shape, y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVzD_4buvw8d"
      },
      "source": [
        "## Train/Test Split\n",
        "\n",
        "In order to validate that our model can generalize to data that it wasn't trained on, it's necessary to create a sperate **testing dataset** that will not be used in training.\n",
        "\n",
        "Within the `model_selection` submodule of Scikit Learn, there's the `train_test_split` that we can use to automatically split the data into training and testing pairs.\n",
        "\n",
        "Here's an explanation of the different parameters taken directly from the function's docstring\n",
        "\n",
        "#### **Parameters**\n",
        "\n",
        "**arrays** : sequence of indexables with same length / shape[0]\n",
        "    Allowed inputs are lists, numpy arrays, scipy-sparse\n",
        "    matrices or pandas dataframes.\n",
        "\n",
        "**test_size** : float, int or None, optional (default=None)\n",
        "    If float, should be between 0.0 and 1.0 and represent the proportion\n",
        "    of the dataset to include in the test split. If int, represents the\n",
        "    absolute number of test samples. If None, the value is set to the\n",
        "    complement of the train size. If train_size is also None, it will\n",
        "    be set to 0.25.\n",
        "\n",
        "**train_size** : float, int, or None, (default=None)\n",
        "    If float, should be between 0.0 and 1.0 and represent the\n",
        "    proportion of the dataset to include in the train split. If\n",
        "    int, represents the absolute number of train samples. If None,\n",
        "    the value is automatically set to the complement of the test size.\n",
        "\n",
        "**random_state** : int, RandomState instance or None, optional (default=None)\n",
        "    If int, random_state is the seed used by the random number generator;\n",
        "    If RandomState instance, random_state is the random number generator;\n",
        "    If None, the random number generator is the RandomState instance used\n",
        "    by np.random.\n",
        "\n",
        "**shuffle** : boolean, optional (default=True)\n",
        "    Whether or not to shuffle the data before splitting. If shuffle=False\n",
        "    then stratify must be None.\n",
        "\n",
        "**stratify** : array-like or None (default=None)\n",
        "    If not None, data is split in a stratified fashion, using this as\n",
        "    the class labels.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aEKUby5MwOUc"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = model_selection.train_test_split(\n",
        "    x, y, test_size=0.1, random_state=42, stratify=y\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9chq57lximz"
      },
      "source": [
        "Please note that the `stratify` parameter works only in the context of classification tasks where there are a fixed amount of possible outputs/targets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QohA1Fh6blL9"
      },
      "source": [
        "# Fitting and predicting: estimator basics\n",
        "\n",
        "Scikit-learn provides dozens of built-in machine learning algorithms and models, called estimators. Each estimator can be fitted to some data using its fit method.\n",
        "\n",
        "Here is a simple example where we fit a Linear Regression to some very basic data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 6,
          "status": "ok",
          "timestamp": 1655312940742,
          "user": {
            "displayName": "Muntadher Al-kaabi",
            "userId": "00221067971932357642"
          },
          "user_tz": -180
        },
        "id": "7IrGMK3_bf3W",
        "outputId": "e7f9f450-86a1-410f-9b09-d122fab5f037"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"\u25b8\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\u25be\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LinearRegression()"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = [[ 1,  2,  3],  # 2 samples, 3 features\n",
        "    [11, 12, 13]]\n",
        "y = [0.5, 0.1]# classes of each sample\n",
        "\n",
        "model = linear_model.LinearRegression()\n",
        "\n",
        "model.fit(x,y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 399,
          "status": "ok",
          "timestamp": 1655312943365,
          "user": {
            "displayName": "Muntadher Al-kaabi",
            "userId": "00221067971932357642"
          },
          "user_tz": -180
        },
        "id": "xzxhbQ0PdWcq",
        "outputId": "7e299cee-0312-4cf8-ee02-8926e6b883a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.5 0.1]\n",
            "[ 0.38 -0.02]\n"
          ]
        }
      ],
      "source": [
        "pred= model.predict(x)  # predict classes of the training data\n",
        "print(pred)\n",
        "pred= model.predict([[4, 5, 6], \n",
        "                    [14, 15, 16]])  # predict classes of new data\n",
        "print(pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jb4V_h7rc-Ls"
      },
      "source": [
        "The `fit` method generally accepts 2 inputs:\n",
        "\n",
        "1. The samples matrix (or design matrix) X. The size of X is typically (n_samples, n_features), which means that samples are represented as rows and features are represented as columns.\n",
        "\n",
        "2. The target values y which are real numbers for regression tasks, or integers for classification (or any other discrete set of values). For unsupervized learning tasks, y does not need to be specified. y is usually 1d array where the i th entry corresponds to the target of the i th sample (row) of X.\n",
        "\n",
        "Both X and y are usually expected to be numpy arrays or equivalent array-like data types, though some estimators work with other formats such as sparse matrices.\n",
        "\n",
        "Once the estimator is fitted, it can be used for predicting target values of new data. You don\u2019t need to re-train the estimator:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mN9b1m-YEqVP"
      },
      "source": [
        "# Linear Regression\n",
        "\n",
        "In statistics, linear regression is a linear approach to modelling the relationship between a set a features, and a desired output. The case of one input feature is called simple linear regression; for more than one, the process is called multiple linear regression.\n",
        "\n",
        "Scikit Learn defines this algorithm in `LinearRegression` class as a part of the `linear_models` module.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euPwTAlozl-z"
      },
      "source": [
        "First, we load the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 6,
          "status": "ok",
          "timestamp": 1655312958796,
          "user": {
            "displayName": "Muntadher Al-kaabi",
            "userId": "00221067971932357642"
          },
          "user_tz": -180
        },
        "id": "urCbsGeMEqVP",
        "outputId": "a1a3beed-4b8e-4045-98a6-fa542405fb29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Diabetes features/input shape: (442, 10)\n",
            "Diabetes target/output shape: (442,)\n"
          ]
        }
      ],
      "source": [
        "x, y = datasets.load_diabetes(return_X_y=True)\n",
        "# normalize the values of x and y\n",
        "y_normalize = preprocessing.MinMaxScaler()\n",
        "y_norm = y_normalize.fit_transform(y.reshape(-1, 1))  # normlize the y\n",
        "\n",
        "x_normalize = preprocessing.StandardScaler()\n",
        "x_norm = x_normalize.fit_transform(x)  # normlize the x\n",
        "\n",
        "print(\"Diabetes features/input shape:\", x.shape)\n",
        "print(\"Diabetes target/output shape:\", y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsXgJi2uzh96"
      },
      "source": [
        "Second, we split the data into 90/10 training/testing split (90% of the data will be used for training while 10% will be used for testing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 493,
          "status": "ok",
          "timestamp": 1655312962127,
          "user": {
            "displayName": "Muntadher Al-kaabi",
            "userId": "00221067971932357642"
          },
          "user_tz": -180
        },
        "id": "tgO8Mj4jlXdZ",
        "outputId": "36c8e198-0f5e-41a2-d88d-3e40831b64c6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((397, 10), (45, 10), (397,), (45,))"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train, x_test, y_train, y_test = model_selection.train_test_split(\n",
        "    x_norm, y_norm.reshape(-1), test_size=0.1, random_state=42\n",
        ")\n",
        "\n",
        "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3L2rnqyzXzV"
      },
      "source": [
        "Third, we train (i.e. `fit`) the model using the training dataset (`x_train` as inputs, `y_train` as targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 6,
          "status": "ok",
          "timestamp": 1655312963309,
          "user": {
            "displayName": "Muntadher Al-kaabi",
            "userId": "00221067971932357642"
          },
          "user_tz": -180
        },
        "id": "Xy0-GOCqEqVQ",
        "outputId": "4d495b7d-5598-40f7-b372-dfb9a879c65b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Weights:\n",
            " [ 0.00295256 -0.03890481  0.07545094  0.04980218 -0.12584691  0.07115817\n",
            "  0.01788275  0.03507649  0.10618591  0.01043328]\n",
            "Bias:\n",
            " 0.39477478088542883\n"
          ]
        }
      ],
      "source": [
        "regressor = (\n",
        "    linear_model.LinearRegression()\n",
        ")  # initialize the parameter of linear  regression model\n",
        "regressor.fit(x_train, y_train)  # training the model on the train data\n",
        "\n",
        "# we can preview the learned coefficients (i.e. weights) and intercept (i.e. bias)\n",
        "\n",
        "print(\"Weights:\\n\", regressor.coef_)\n",
        "print(\"Bias:\\n\", regressor.intercept_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwY6r_g5zTMN"
      },
      "source": [
        "Fourth, we'll feed the test set into the trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SC2kNUdaAe7_"
      },
      "outputs": [],
      "source": [
        "y_pred = regressor.predict(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edEogEf-zRCl"
      },
      "source": [
        "Finally, we'll evaluate the predicted output against the ground-truth values in `y_test` using Scikit Learn's `metrics` module\n",
        "\n",
        "One of the most used metrics to evaluate regression models is `mean_squared_error` which has the following formula: $$\\frac{1}{n}\\sum_{i=1}^{n}(\\hat y_i - y_i)^2$$\n",
        "\n",
        "Where `n` is the total number of examples evaluated (in this case 45), $\\hat y$ is the predicted value (here `y_pred`) and $y$ is the ground-truth value (here `y_test`)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 6,
          "status": "ok",
          "timestamp": 1655312966852,
          "user": {
            "displayName": "Muntadher Al-kaabi",
            "userId": "00221067971932357642"
          },
          "user_tz": -180
        },
        "id": "_2ma5hdDA6tX",
        "outputId": "c05c3168-13b2-4fdb-aaa0-14c3c3b9c0c3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.02662901220648913"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "metrics.mean_squared_error(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZSazzIi1xar"
      },
      "source": [
        "# Logistic Regression\n",
        "\n",
        "In statistics, the logistic model (or logit model) is used to model the probability of a certain class or event existing such as pass/fail, win/lose, alive/dead or healthy/sick. This can be extended to model several classes of events such as determining whether an image contains a cat, dog, lion, etc. Each object being detected in the image would be assigned a probability between 0 and 1, with a sum of one.\n",
        "\n",
        "\n",
        "Scikit Learn defines this algorithm in `LogisticRegression` class as a part of the `linear_models` module.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lq8iQ7Sl1xas"
      },
      "source": [
        "First, we load the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 424,
          "status": "ok",
          "timestamp": 1655312969046,
          "user": {
            "displayName": "Muntadher Al-kaabi",
            "userId": "00221067971932357642"
          },
          "user_tz": -180
        },
        "id": "YTS2cFdD1xas",
        "outputId": "906679fb-ad5c-4539-ac68-a421d1eee4ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Breast Cancer features/input shape: (569, 30)\n",
            "Breast Cancer target/output shape: (569,)\n"
          ]
        }
      ],
      "source": [
        "x, y = datasets.load_breast_cancer(return_X_y=True)\n",
        "# normalize the values of x\n",
        "x_normalize = preprocessing.StandardScaler()\n",
        "x_norm = x_normalize.fit_transform(x)\n",
        "print(\"Breast Cancer features/input shape:\", x_norm.shape)\n",
        "print(\"Breast Cancer target/output shape:\", y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZIGpVe_1xat"
      },
      "source": [
        "Second, we split the data into 90/10 training/testing split (90% of the data will be used for training while 10% will be used for testing)\n",
        "\n",
        "Since this is a classification problem (we only have two possible outputs, 1 or 0), we can use the `stratify` parameter to ensure that the two possible output values are distributed proportionally between the training and testing sets and preserve the data's original distribution across the two sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 549,
          "status": "ok",
          "timestamp": 1655312971415,
          "user": {
            "displayName": "Muntadher Al-kaabi",
            "userId": "00221067971932357642"
          },
          "user_tz": -180
        },
        "id": "Vh9i-abM1xat",
        "outputId": "01f1ab71-6442-414b-cb0a-56f6008250d7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((512, 30), (57, 30), (512,), (57,))"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train, x_test, y_train, y_test = model_selection.train_test_split(\n",
        "    x_norm, y, test_size=0.1, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQBL3xRW1xau"
      },
      "source": [
        "Third, we train (i.e. `fit`) the model using the training dataset (`x_train` as inputs, `y_train` as targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 7,
          "status": "ok",
          "timestamp": 1655312971847,
          "user": {
            "displayName": "Muntadher Al-kaabi",
            "userId": "00221067971932357642"
          },
          "user_tz": -180
        },
        "id": "C_rv1UZf1xau",
        "outputId": "ac8b6fe5-b0d1-4dee-952e-911938ae2f4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Weights:\n",
            " [ 0.00295256 -0.03890481  0.07545094  0.04980218 -0.12584691  0.07115817\n",
            "  0.01788275  0.03507649  0.10618591  0.01043328]\n",
            "Bias:\n",
            " 0.39477478088542883\n"
          ]
        }
      ],
      "source": [
        "classifier = linear_model.LogisticRegression()\n",
        "classifier.fit(x_train, y_train)\n",
        "\n",
        "# we can preview the learned coefficients (i.e. weights) and intercept (i.e. bias)\n",
        "\n",
        "print(\"Weights:\\n\", regressor.coef_)\n",
        "print(\"Bias:\\n\", regressor.intercept_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xE2N6-SR1xau"
      },
      "source": [
        "Fourth, we'll feed the test set into the trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hV_LmBvP1xav"
      },
      "outputs": [],
      "source": [
        "y_pred = classifier.predict(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ReSoDvxc1xav"
      },
      "source": [
        "Finally, we'll evaluate the predicted output against the ground-truth values in `y_test` using Scikit Learn's `metrics` module\n",
        "\n",
        "One of the most used metrics to evaluate classification models is `accuracy_score` which calculates the precentage of the examples that the trained classifier guessed correctly\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 6,
          "status": "ok",
          "timestamp": 1655312976677,
          "user": {
            "displayName": "Muntadher Al-kaabi",
            "userId": "00221067971932357642"
          },
          "user_tz": -180
        },
        "id": "6WjQ-aSI1xav",
        "outputId": "0ec58b7f-04cf-4232-b8ea-64d526723350"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9649122807017544"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "metrics.accuracy_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0HWW8lfVFfc"
      },
      "source": [
        "# Pipeline \n",
        "Scikit-learn's pipeline class is a useful tool for encapsulating multiple different transformers alongside an estimator into one object, so that you only have to call your important methods once `( fit() , predict() , etc).`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-UnRk1OVbqP"
      },
      "outputs": [],
      "source": [
        "# Import the sklearn pipeline\n",
        "from sklearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9Lv2nMmWez0"
      },
      "outputs": [],
      "source": [
        "# Download the dataset \n",
        "x, y = datasets.load_breast_cancer(return_X_y=True)\n",
        "# Split the dataset to train and test \n",
        "x_train, x_test, y_train, y_test = model_selection.train_test_split(\n",
        "    x, y, test_size=0.1, random_state=42, stratify=y\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OP786qxEWXoS"
      },
      "source": [
        "The first step in building the pipeline is to define each transformer type. The convention here is generally to create transformers for the different variable types. In the code below I have created a numeric transformer which applies a StandardScaler, and includes a SimpleImputer to fill in any missing values. This is a really nice function in scikit-learn and has a number of options for filling missing values. I have chosen to use median but another method may result in better performance. The categorical transformer also has a SimpleImputer with a different fill method, and leverages OneHotEncoder to transform the categorical values into integers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 370,
          "status": "ok",
          "timestamp": 1655314427549,
          "user": {
            "displayName": "Muntadher Al-kaabi",
            "userId": "00221067971932357642"
          },
          "user_tz": -180
        },
        "id": "_VQDmA6NVhbM",
        "outputId": "1f123744-f6a7-482c-bb59-4f11c85dc14f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Pipeline(steps=[('scaler', StandardScaler()),\n",
              "                ('Logistic_R', LogisticRegression())])"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create the sklearn pipeline \n",
        "pipe = Pipeline([('scaler', preprocessing.StandardScaler()),\n",
        "                 ('Logistic_R', linear_model.LogisticRegression())])\n",
        "\n",
        "# fit the pipeline \n",
        "pipe.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 597,
          "status": "ok",
          "timestamp": 1655314479639,
          "user": {
            "displayName": "Muntadher Al-kaabi",
            "userId": "00221067971932357642"
          },
          "user_tz": -180
        },
        "id": "mKjjiGTbbSTl",
        "outputId": "aa586a9c-471f-496e-da5e-6014846717c3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9649122807017544"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Calculate the Accuracy of the model\n",
        "pipe.score(x_test, y_test)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "1- Scikit_Learn.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "b667cebad148e7b094a58ee81f940c685de1dd70a003a9ccdca4a5792431bee5"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}